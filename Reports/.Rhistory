# Set up linear regression model 1
model_1 <- glm(high_rating ~ year + length + budget + votes + genre ,
data = df,
family = binomial)
# Durbin-Watson checking
dwtest(model_1)
# Check for duplicate values and abnormal patterns
dup<-sum(duplicated(df))
# Set up linear regression model 2
model_2 <- glm(high_rating ~ year + length + budget
+ votes + genre,
data = df, family = binomial)
# Calculate VIF
vif(model_2)
# Calculate standardized residuals
model_residuals <- rstandard(model_1)
# Identify outliers with an absolute value greater than 3
outliers <- which(abs(model_residuals) > 3)
print(outliers)
print(df[outliers, ])
# Calculate leverage values
leverage <- hatvalues(model_1)
# Calculate the leverage threshold
threshold <- 2 * (length(coef(model_1)) / nrow(df))
# Identify points with high leverage
high_leverage <- which(leverage > threshold)
lev<-df[high_leverage, c("year", "length", "budget", "votes", "high_rating")]
cooks_values <- cooks.distance(model_1)
influential_points <- which(cooks_values > 1)
print(intersect(high_leverage, influential_points))
write.csv(x = df,file = "Cleaned_data.csv",row.names = FALSE)
#| echo: true
#| fig.cap: "Distribution of IMDB Rating"
#| fig-align: center
ggplot(df, aes(x=rating))+
geom_histogram(binwidth=0.5,fill="blue",alpha=0.6)+
theme_minimal()
#| label: fig-indicators
#| fig-cap: "key indicators influencing rating"
# Rating vs Budget
p1<-ggplot(df,aes(x=budget,y=rating))+
geom_point(alpha=0.5,color="blue")+
geom_smooth(method="lm",color="red")+
labs(title="Rating vs Budget",x="Budget",y="IMDB Rating")
# Rating vs Votes
p2<-ggplot(df,aes(x=votes,y=rating))+
geom_point(alpha=0.5,color="purple")+
geom_smooth(method="lm",color="red")+
labs(title="Rating vs Votes",x="Votes",y="IMDB Rating")
# Rating by Genre
p3<-df %>%
group_by(genre)%>%
summarise(avg_rating=mean(rating,na.rm=TRUE))%>%
ggplot(aes(x=reorder(genre,avg_rating),y=avg_rating,fill=genre))+
geom_bar(stat="identity",show.legend = FALSE)+
labs(title="Average Rating by Genre",x="Genre",y="Average Rating")
grid.arrange(p1,p2,p3,nrow=1)
#| label: fig-relationships
#| fig-cap: "Relationships Between Movie Length, Budget, Votes, and Rating"
ggpairs(df,c("length", "budget", "votes","rating"))
#| echo: false
#| results: markup
options(scipen = 999)
# construct a GLM based on the binomial distribution
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df,method = "brglmFit"
)
# summary of the model
summary(model)
#Check which samples have predicted probabilities exactly equal to 0 or 1
pred_probs <- predict(model, type = "response")
summary(pred_probs)
#Find and display the samples
df_extreme <- df[pred_probs %in% c(0, 1), ]
print(df_extreme)
#| results: markup
# establish models
null_model <- glm(high_rating ~ 1, family = binomial(), data = df)
# likelihood ratio test
anova_result <- anova(null_model, model, test = "Chisq")
print(anova_result)
#| results: markup
# Wald test（Type III test???
wald_test <- Anova(model, type = "III", test = "Wald")
print(wald_test)
#| results: markup
df$predicted_prob <- predict(model, type = "response")
# Hosmer-Lemeshow test
hl_test <- hoslem.test(as.numeric(df$high_rating), df$predicted_prob, g = 10)
# outcome
print(hl_test)
#| echo: true
#| label: fig-residual
#| fig.cap: "Residuals vs Fitted"
#| fig-align: center
# residuals vs fitted
df_residuals<-data.frame(
Fitted=fitted(model),
Residuals=residuals(model,type = "response")
)
ggplot(df_residuals,aes(x=Fitted,y=Residuals))+
geom_point(color="blue",alpha=0.6)+
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(x="Fitted Values",y="Residuals")
ggplot(df_residuals,aes(x=df$film_id,y=Residuals))+
geom_point(color="blue",alpha=0.6)+
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(x="film_id",y="Residuals")
# Set up linear regression model 2
model_2 <- glm(high_rating ~ year + length + budget
+ votes + genre,
data = df, family = binomial)
# Calculate VIF
vif(model_2)
#| label: fig-indicators
#| fig-cap: "key indicators influencing rating"
# Rating vs Budget
p1<-ggplot(df,aes(x=budget,y=rating))+
geom_point(alpha=0.5,color="blue")+
geom_smooth(method="lm",color="red")+
labs(title="Rating vs Budget",x="Budget",y="IMDB Rating")
# Rating vs Votes
p2<-ggplot(df,aes(x=votes,y=rating))+
geom_point(alpha=0.5,color="purple")+
geom_smooth(method="lm",color="red")+
labs(title="Rating vs Votes",x="Votes",y="IMDB Rating")
# Rating by Genre
p3<-df %>%
group_by(genre)%>%
summarise(avg_rating=mean(rating,na.rm=TRUE))%>%
ggplot(aes(x=reorder(genre,avg_rating),y=avg_rating,fill=genre))+
geom_bar(stat="identity",show.legend = FALSE)+
labs(title="Average Rating by Genre",x="Genre",y="Average Rating")
grid.arrange(p1,p2,p3,nrow=1)
#| echo: false
#| results: markup
options(scipen = 999)
# construct a GLM based on the binomial distribution
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df,method = "brglmFit"
)
# summary of the model
tidy_model <- tidy(model)
#| label: libraries
#Load the required R packages
library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
library(pROC)
library(brglm2)
library(ggplot2)
library(GGally)
library(gridExtra)
library(ResourceSelection)
library(caret)
library(broom)
library(knitr)
library(kableExtra)
install.packages("kableExtra")
#| label: libraries
#Load the required R packages
library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
library(pROC)
library(brglm2)
library(ggplot2)
library(GGally)
library(gridExtra)
library(ResourceSelection)
library(caret)
library(broom)
library(knitr)
library(kableExtra)
#| label: libraries
#Load the required R packages
library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
library(pROC)
library(brglm2)
library(ggplot2)
library(GGally)
library(gridExtra)
library(ResourceSelection)
library(caret)
library(broom)
library(knitr)
library(kableExtra)
#| label: libraries
#Load the required R packages
library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
library(pROC)
library(brglm2)
library(ggplot2)
library(GGally)
library(gridExtra)
library(ResourceSelection)
library(caret)
library(broom)
library(knitr)
library(kableExtra)
#read the data
df <- read.csv("../Data/dataset09.csv", stringsAsFactors = FALSE)
str<-str(df)
summary<-summary(df)
print(summary)
mcar_test(df["length"])
df <- df %>% filter(!is.na(length))
# convert y
df$high_rating <- ifelse(df$rating > 7, 1, 0)
df$genre <- factor(df$genre)
df$high_rating <- factor(df$high_rating)
df$years_since <- 2025 - df$year
# Set up linear regression model 1
model_1 <- glm(high_rating ~ year + length + budget + votes + genre ,
data = df,
family = binomial)
# Durbin-Watson checking
dwtest(model_1)
# Check for duplicate values and abnormal patterns
dup<-sum(duplicated(df))
# Set up linear regression model 2
model_2 <- glm(high_rating ~ year + length + budget
+ votes + genre,
data = df, family = binomial)
# Calculate VIF
vif(model_2)
# Calculate standardized residuals
model_residuals <- rstandard(model_1)
# Identify outliers with an absolute value greater than 3
outliers <- which(abs(model_residuals) > 3)
print(outliers)
print(df[outliers, ])
# Calculate leverage values
leverage <- hatvalues(model_1)
# Calculate the leverage threshold
threshold <- 2 * (length(coef(model_1)) / nrow(df))
# Identify points with high leverage
high_leverage <- which(leverage > threshold)
lev<-df[high_leverage, c("year", "length", "budget", "votes", "high_rating")]
cooks_values <- cooks.distance(model_1)
influential_points <- which(cooks_values > 1)
print(intersect(high_leverage, influential_points))
write.csv(x = df,file = "Cleaned_data.csv",row.names = FALSE)
#| echo: true
#| fig.cap: "Distribution of IMDB Rating"
#| fig-align: center
ggplot(df, aes(x=rating))+
geom_histogram(binwidth=0.5,fill="blue",alpha=0.6)+
theme_minimal()
#| label: fig-indicators
#| fig-cap: "key indicators influencing rating"
# Rating vs Budget
p1<-ggplot(df,aes(x=budget,y=rating))+
geom_point(alpha=0.5,color="blue")+
geom_smooth(method="lm",color="red")+
labs(title="Rating vs Budget",x="Budget",y="IMDB Rating")
# Rating vs Votes
p2<-ggplot(df,aes(x=votes,y=rating))+
geom_point(alpha=0.5,color="purple")+
geom_smooth(method="lm",color="red")+
labs(title="Rating vs Votes",x="Votes",y="IMDB Rating")
# Rating by Genre
p3<-df %>%
group_by(genre)%>%
summarise(avg_rating=mean(rating,na.rm=TRUE))%>%
ggplot(aes(x=reorder(genre,avg_rating),y=avg_rating,fill=genre))+
geom_bar(stat="identity",show.legend = FALSE)+
labs(title="Average Rating by Genre",x="Genre",y="Average Rating")
grid.arrange(p1,p2,p3,nrow=1)
#| label: fig-relationships
#| fig-cap: "Relationships Between Movie Length, Budget, Votes, and Rating"
ggpairs(df,c("length", "budget", "votes","rating"))
#| echo: false
#| results: markup
options(scipen = 999)
# construct a GLM based on the binomial distribution
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df,method = "brglmFit"
)
# summary of the model
tidy_model <- tidy(model)
kable(tidy_model, digits = 3, caption = "Regression Model Coefficients") %>%
kable_styling(latex_options = c("hold_position", "striped"))
#Check which samples have predicted probabilities exactly equal to 0 or 1
pred_probs <- predict(model, type = "response")
summary(pred_probs)
#Find and display the samples
df_extreme <- df[pred_probs %in% c(0, 1), ]
print(df_extreme)
#| results: markup
# establish models
null_model <- glm(high_rating ~ 1, family = binomial(), data = df)
# likelihood ratio test
anova_result <- anova(null_model, model, test = "Chisq")
print(anova_result)
#| results: markup
# Wald test（Type III test???
wald_test <- Anova(model, type = "III", test = "Wald")
print(wald_test)
#| results: markup
df$predicted_prob <- predict(model, type = "response")
# Hosmer-Lemeshow test
hl_test <- hoslem.test(as.numeric(df$high_rating), df$predicted_prob, g = 10)
# outcome
print(hl_test)
#| echo: true
#| label: fig-residual
#| fig.cap: "Residuals vs Fitted"
#| fig-align: center
# residuals vs fitted
df_residuals<-data.frame(
Fitted=fitted(model),
Residuals=residuals(model)
)
ggplot(df_residuals,aes(x=Fitted,y=Residuals))+
geom_point(color="blue",alpha=0.6)+
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(x="Fitted Values",y="Residuals")
#| label: fig-QQ
#| fig.cap: "Normal QQ plot"
#| fig-align: center
# Q-Q plot
qq_data<-data.frame(
sample=residuals(model),
theoretical=qqnorm(residuals(model))
)
#| label: libraries
#Load the required R packages
library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
library(pROC)
library(brglm2)
library(ggplot2)
library(GGally)
library(gridExtra)
library(ResourceSelection)
library(caret)
library(broom)
library(knitr)
library(kableExtra)
#read the data
df <- read.csv("../Data/dataset09.csv", stringsAsFactors = FALSE)
str<-str(df)
summary<-summary(df)
print(summary)
mcar_test(df["length"])
df <- df %>% filter(!is.na(length))
# convert y
df$high_rating <- ifelse(df$rating > 7, 1, 0)
df$genre <- factor(df$genre)
df$high_rating <- factor(df$high_rating)
df$years_since <- 2025 - df$year
# Set up linear regression model 1
model_1 <- glm(high_rating ~ year + length + budget + votes + genre ,
data = df,
family = binomial)
# Durbin-Watson checking
dwtest(model_1)
# Check for duplicate values and abnormal patterns
dup<-sum(duplicated(df))
# Set up linear regression model 2
model_2 <- glm(high_rating ~ year + length + budget
+ votes + genre,
data = df, family = binomial)
# Calculate VIF
vif(model_2)
# Calculate standardized residuals
model_residuals <- rstandard(model_1)
# Identify outliers with an absolute value greater than 3
outliers <- which(abs(model_residuals) > 3)
print(outliers)
print(df[outliers, ])
# Calculate leverage values
leverage <- hatvalues(model_1)
# Calculate the leverage threshold
threshold <- 2 * (length(coef(model_1)) / nrow(df))
# Identify points with high leverage
high_leverage <- which(leverage > threshold)
lev<-df[high_leverage, c("year", "length", "budget", "votes", "high_rating")]
cooks_values <- cooks.distance(model_1)
influential_points <- which(cooks_values > 1)
print(intersect(high_leverage, influential_points))
write.csv(x = df,file = "Cleaned_data.csv",row.names = FALSE)
#| echo: true
#| fig.cap: "Distribution of IMDB Rating"
#| fig-align: center
ggplot(df, aes(x=rating))+
geom_histogram(binwidth=0.5,fill="blue",alpha=0.6)+
theme_minimal()
#| label: fig-indicators
#| fig-cap: "key indicators influencing rating"
# Rating vs Budget
p1<-ggplot(df,aes(x=budget,y=rating))+
geom_point(alpha=0.5,color="blue")+
geom_smooth(method="lm",color="red")+
labs(title="Rating vs Budget",x="Budget",y="IMDB Rating")
# Rating vs Votes
p2<-ggplot(df,aes(x=votes,y=rating))+
geom_point(alpha=0.5,color="purple")+
geom_smooth(method="lm",color="red")+
labs(title="Rating vs Votes",x="Votes",y="IMDB Rating")
# Rating by Genre
p3<-df %>%
group_by(genre)%>%
summarise(avg_rating=mean(rating,na.rm=TRUE))%>%
ggplot(aes(x=reorder(genre,avg_rating),y=avg_rating,fill=genre))+
geom_bar(stat="identity",show.legend = FALSE)+
labs(title="Average Rating by Genre",x="Genre",y="Average Rating")
grid.arrange(p1,p2,p3,nrow=1)
#| echo: false
#| results: markup
options(scipen = 999)
# construct a GLM based on the binomial distribution
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df,method = "brglmFit"
)
# summary of the model
tidy_model <- tidy(model)
kable(tidy_model, digits = 3, caption = "Regression Model Coefficients") %>%
kable_styling(latex_options = c("hold_position", "striped"))
#| results: markup
# establish models
null_model <- glm(high_rating ~ 1, family = binomial(), data = df)
# likelihood ratio test
anova_result <- anova(null_model, model, test = "Chisq")
print(anova_result)
#| results: markup
# establish models
null_model <- glm(high_rating ~ 1, family = binomial(), data = df)
# likelihood ratio test
anova_result <- anova(null_model, model, test = "Chisq")
print(anova_result)
#| results: markup
# Wald test（Type III test???
wald_test <- Anova(model, type = "III", test = "Wald")
print(wald_test)
#| results: markup
df$predicted_prob <- predict(model, type = "response")
# Hosmer-Lemeshow test
hl_test <- hoslem.test(as.numeric(df$high_rating), df$predicted_prob, g = 10)
# outcome
print(hl_test)
#| echo: true
#| label: fig-residual
#| fig.cap: "Residuals vs Fitted"
#| fig-align: center
# residuals vs fitted
df_residuals<-data.frame(
Fitted=fitted(model),
Residuals=residuals(model)
)
ggplot(df_residuals,aes(x=Fitted,y=Residuals))+
geom_point(color="blue",alpha=0.6)+
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(x="Fitted Values",y="Residuals")
#| echo: true
#| label: fig-residual
#| fig.cap: "Residuals vs Fitted"
#| fig-align: center
# residuals vs fitted
df_residuals<-data.frame(
Fitted=fitted(model),
Residuals=residuals(model)
)
ggplot(df_residuals,aes(x=Fitted,y=Residuals))+
geom_point(color="blue",alpha=0.6)+
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(x="Fitted Values",y="Residuals")
ggplot(df_residuals,aes(x=df$film_id,y=Residuals))+
geom_point(color="blue",alpha=0.6)+
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(x="film_id",y="Residuals")
#| echo: true
#| label: fig-residual
#| fig.cap: "Residuals vs Fitted"
#| fig-align: center
# residuals vs fitted
df_residuals<-data.frame(
Fitted=fitted(model),
Residuals=residuals(model,type = "response")
)
ggplot(df_residuals,aes(x=Fitted,y=Residuals))+
geom_point(color="blue",alpha=0.6)+
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(x="Fitted Values",y="Residuals")
ggplot(df_residuals,aes(x=df$film_id,y=Residuals))+
geom_point(color="blue",alpha=0.6)+
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(x="film_id",y="Residuals")
