---
title: "Analyzing Properties Influencing IMDB Ratings based on a Logistic Regression"
author: "Diwen Jiang, Wei Xiang, Zilu Liu, Haoran Jing, Wenli Zhang"
number-sections: true
format:
  pdf: default
editor_options: 
  chunk_output_type: console
execute:
  echo: true
  eval: true
  warning: false
  message: false
  results: asis
---

# Introduction

IMDB ratings significantly influence audience preferences and the film industry. This study aims to analyze which factors contribute to higher IMDB ratings, specifically whether a movie receives a score greater than 7. Using the IMDB film data set, we employ logistic regression to identify key predictors. The findings provide insights into which factors drive higher ratings by data processing, visualization and model evaluation.

```{r}
#| label: libraries
#Load the required R packages
library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
library(pROC)
library(brglm2)
library(ggplot2)
library(GGally)
library(gridExtra)
library(ResourceSelection)
library(caret)
library(broom)
library(knitr)
library(kableExtra)
```

# Data cleaning

Before data modelling, we first check whether there are abnormal or missing values.

```{r}
#read the data
df <- read.csv("../Data/dataset09.csv", stringsAsFactors = FALSE)
str<-str(df)
summary<-summary(df)
print(summary)
```

At this stage, we can clearly observe that the **length** variable contains 127 missing values. No other obvious anomalies are present in the data set. However, further discussion and analysis are needed.

## Handle missing values

Therefore, we should handle the missing values.The first step is to check whether the missing values are Missing Completely at Random (MCAR).

```{r}
mcar_test(df["length"])
```

p value is equal to 1 (far greater than 0.05), meaning there is no systematic missing pattern. statistic is equal to 0 indicates that the MCAR assumption perfectly matches the missing data pattern. df is equal to 0 may suggest that the dataset has few variables or a simple missing pattern, implying that the missing data is completely random (MCAR) and can be directly removed.

```{r}
df <- df %>% filter(!is.na(length))
```

## Set labels and data types

The dependent variable must be categorical, with at least one independent variable. Independent variables can be either continuous or categorical.

```{r}
# convert y
df$high_rating <- ifelse(df$rating > 7, 1, 0)
```

Additionally, the "genre" variable is a multinomial categorical variable, so it needs to be converted into to a factor type.

```{r}
df$genre <- factor(df$genre)
df$high_rating <- factor(df$high_rating)
```

Now, all variables meet the requirements of this assumption.

## Convert the year column to year_since

```{r}
df$years_since <- 2025 - df$year
```

Each observation must be independent. The categories of categorical variables (including both the dependent and independent variables) must be exhaustive and mutually exclusive.

## Observations independent 

Check whether the observations are independent.

The "years_since" variable may introduce dependency in the data, so we use the Durbin-Watson test to check for autocorrelation:

```{r}

# Set up linear regression model 1
model_1 <- glm(high_rating ~ year + length + budget + votes + genre ,
               data = df, 
               family = binomial)

# Durbin-Watson checking
dwtest(model_1)
```

p-value is equal to 0.9514, which is far greater than 0.05, indicating that the independence assumption is satisfied.

```{r}
# Check for duplicate values and abnormal patterns
dup<-sum(duplicated(df))
```

There are no duplicate values in the dataset.This result Indicates that no films are classified into multiple genres simultaneously.

## Minimum data requirements

Logistic regression requires the assumption that: The minimum sample size should be 15 times the number of independent variables.The cleaned dataset contains 2,874 entries, which clearly supports this assumption.

## VIF

There should be no multicollinearity among independent variables.

VIF calculates the correlation between an independent variable and other independent variables.

```{r}
# Set up linear regression model 2
model_2 <- glm(high_rating ~ year + length + budget 
             + votes + genre, 
             data = df, family = binomial)

# Calculate VIF
vif(model_2)
```

All VIF less than 5, indicating that there is no severe multicollinearity.

## Outliers and leverage points

There should be no significant outliers, leverage points, or influential points in the data.

Check for outliers:

```{r}
# Calculate standardized residuals
model_residuals <- rstandard(model_1)

# Identify outliers with an absolute value greater than 3
outliers <- which(abs(model_residuals) > 3)

print(outliers)
```

We found that rows 917, 1870, and 2388 may contain outliers .Now, print these three rows for inspection.

```{r}
print(df[outliers, ])
```

After inspection, these three values are considered normal data and will be retained for now.

Check for leverage points:

```{r}
# Calculate leverage values
leverage <- hatvalues(model_1)

# Calculate the leverage threshold
threshold <- 2 * (length(coef(model_1)) / nrow(df))

# Identify points with high leverage
high_leverage <- which(leverage > threshold)
```

A large number of leverage values have been detected, requiring further investigation.

```{r}
lev<-df[high_leverage, c("year", "length", "budget", "votes", "high_rating")]
```

Combine Cook's Distance to check which points are truly influential.

```{r}
cooks_values <- cooks.distance(model_1)
influential_points <- which(cooks_values > 1)

print(intersect(high_leverage, influential_points))

```

## Output

```{r}
write.csv(x = df,file = "Cleaned_data.csv",row.names = FALSE)
```

No observation is both a high leverage point and a \*\*highly influential point. Since the leverage points and Cook's Distance tests collectively suggest retaining the previously identified outliers, they will be kept. Now, the data supports this assumption.

The assumption that continuous independent variables have a linear relationship with the logit-transformed dependent variable will be further explored in later sections. This concludes the data preprocessing phase.

# Explanatory data analysis

## Distribution of IMDB rating

```{r}
#| echo: true
#| fig.cap: "Distribution of IMDB Rating"
#| fig-align: center
ggplot(df, aes(x=rating))+
  geom_histogram(binwidth=0.5,fill="blue",alpha=0.6)+
  theme_minimal()
```

Most of the IMDB scores are concentrated in 4-8 points, with a slightly right distribution. The dependent variable must be categorical, with at least one independent variable. Independent variables can be either continuous or categorical. We can see that the target response variable should be whether films are rated by IMDb as greater than 7 or not. Therefore, the response variable needs to be transformed.

## key indicators influencing rating

```{r}
#| label: fig-indicators
#| fig-cap: "key indicators influencing rating"
# Rating vs Budget
p1<-ggplot(df,aes(x=budget,y=rating))+
  geom_point(alpha=0.5,color="blue")+
  geom_smooth(method="lm",color="red")+
  labs(title="Rating vs Budget",x="Budget",y="IMDB Rating")
# Rating vs Votes
p2<-ggplot(df,aes(x=votes,y=rating))+
  geom_point(alpha=0.5,color="purple")+
  geom_smooth(method="lm",color="red")+
  labs(title="Rating vs Votes",x="Votes",y="IMDB Rating")
# Rating by Genre
p3<-df %>% 
  group_by(genre)%>%
  summarise(avg_rating=mean(rating,na.rm=TRUE))%>%
  ggplot(aes(x=reorder(genre,avg_rating),y=avg_rating,fill=genre))+
  geom_bar(stat="identity",show.legend = FALSE)+
  labs(title="Avg Rating by Genre",x="Genre",y="Average Rating")+
  theme(axis.text.x=element_text(angle=45,hjust=1))
grid.arrange(p1,p2,p3,nrow=1)
```

From the plots, we can see that movies with higher budges tend to have higher ratings, but the relevance is not obvious; There is a slight negative relationship trend in the score and the number of votes, but the intensity is very weak; There are significant differences in the average scores of different film types, and some genres (documentaries and drama films) have higher scores.

```{r}
#| label: fig-relationships
#| fig-cap: "Relationships Between Movie Length, Budget, Votes, and Rating"
ggpairs(df,c("length", "budget", "votes","rating"))
```

From the correlation plots, we can see that the negative correlation of length and rating is the most obvious, indicating that long movies tend to have lower scores. In addition, the correlation between all variables is relatively weak, which means they can be used as independent variables in the logical regression model.

\newpage

# Formal analysis

## fitting model

```{r}
#| echo: false
#| results: markup
options(scipen = 999)

# construct a GLM based on the binomial distribution
model <- glm(
  high_rating ~ years_since + length + budget + votes + genre,
  family = binomial(link = 'logit'),
  data = df,method = "brglmFit"
)

# summary of the model
tidy_model <- tidy(model)

kable(tidy_model, digits = 3, caption = "Regression Model Coefficients") %>%
  kable_styling(latex_options = c("hold_position", "striped"))
```

It is observed that in some cases the model produces predicted probabilities of exactly 0 or 1. This may be due to variables such as budget or votes having a very large range of values, which affects numerical computations and causes issues like quasi-complete separation in logistic regression.

```{r}
#Check which samples have predicted probabilities exactly equal to 0 or 1
pred_probs <- predict(model, type = "response")
summary(pred_probs)
#Find and display the samples
df_extreme <- df[pred_probs %in% c(0, 1), ]
print(df_extreme)
```

However, "df_extreme" is empty, indicating that there are no samples with predicted probabilities exactly equal to 0 or 1 ??? they are merely close to 0 or 1. Therefore, no adjustment is necessary.

## **Likelihood Ratio Test**

```{r}
#| results: markup
# establish models
null_model <- glm(high_rating ~ 1, family = binomial(), data = df)


# likelihood ratio test
anova_result <- anova(null_model, model, test = "Chisq")
print(anova_result)
```

**p \< 0.05** indicat that the compregensive model is significantly better than the benchmark model.

## **Wald Test**

```{r}
#| results: markup
# Wald testï¼ˆType III test???
wald_test <- Anova(model, type = "III", test = "Wald")
print(wald_test)
```

**p \< 0.05** indicate that all variables are statistically significant.

## **Hosmer-Lemeshow test**

```{r}
#| results: markup
df$predicted_prob <- predict(model, type = "response")

# Hosmer-Lemeshow test
hl_test <- hoslem.test(as.numeric(df$high_rating), df$predicted_prob, g = 10)

# outcome
print(hl_test)
```

**p \> 0.05** indicate that a good fit of the model.

## residual analysis

```{r}
#| echo: true
#| label: fig-residual
#| fig.cap: "Residuals vs Fitted"
#| fig-align: center
# residuals vs fitted
df_residuals<-data.frame(
  Fitted=fitted(model),
  Residuals=residuals(model,type = "response")
)
ggplot(df_residuals,aes(x=Fitted,y=Residuals))+
  geom_point(color="blue",alpha=0.6)+
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(x="Fitted Values",y="Residuals")

ggplot(df_residuals,aes(x=df$film_id,y=Residuals))+
  geom_point(color="blue",alpha=0.6)+
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(x="film_id",y="Residuals")
```

The first plot shows the typical residual pattern of logistic regression, indicating that standard residual analysis methods are not suitable. Instead, it is better to evaluate the model using AUC, confusion matrix, or other appropriate metrics.

The second plot suggests that the residuals are randomly distributed without clear trends or autocorrelation, indicating that the model is likely reasonable overall.

## ROC curve and AUC value

```{r}
#| label: fig-ROC
#| fig.cap: "ROC Curve"
#| fig-align: center
# prediction probability
pred_prob <- predict(model, type = "response")

# ROC curve
roc_curve <- roc(response = df$high_rating, predictor = pred_prob)
par(mfrow=c(1,1))
par(pty="s")
plot(roc_curve, col="blue",lwd=2)
auc_value <- auc(roc_curve)
cat("AUC =", auc_value, "\n")
```

the AUC value is 0.9566, indicating that the model performance is good, and it can accurately classify movies with IMDb scores above 7.

```{r}
# prediction class
pred_class <- ifelse(pred_prob > 0.5, 1, 0)

# precision
metrics <- confusionMatrix(as.factor(pred_class), as.factor(df$high_rating))
print(metrics)
```

From the confusion matrix, we can see that the accuracy score is 0.8946, indicating that the model perform well in classification. What's more, the sensitivity score is 0.9282, indicating that the model perform well in the movies with high rating.

# Conclusion

In conclusion, this study analyzed factors influencing whether a movie receives an IMDB rating above 7 using logistic regression. Movie length, budget and the number of votes are key indicators. The model achieved high accuracy (0.8946) and AUC (0.9566) demonstrating a strong classification performance. It effectively identified high-rated movies (0.9282 sensitivity) but showed moderate accuracy for low-rated movies (0.8322 specificity).

# Future Work

In this analysis, we found that the ROC curve demonstrated a good model fit. During the model diagnostics, we also observed predicted probabilities that were very close to 0 and 1. We suspect that this may be due to the presence of certain categorical predictors with sparse categories, which could be affecting the model's stability. Adding adding interaction term or log-transformation items may improve model performance. These insights can help filmmakers produce movies and better marketing. Furthermore, applying machine learning techniques such as using a Random Forest and neural network to handle this binary classification problem may yield better performance and more robust results.
