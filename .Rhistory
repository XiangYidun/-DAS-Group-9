library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
library(pROC)
df <- read.csv("dataset09.csv", stringsAsFactors = FALSE)
str(df)
summary(df)
mcar_test(df["length"])
df <- df %>% filter(!is.na(length))
df$high_rating <- ifelse(df$rating > 7, 1, 0)
df$genre <- factor(df$genre)
df$high_rating <- factor(df$high_rating)
df$years_since <- 2025 - df$year
# Set up linear regression model 1
model_1 <- glm(high_rating ~ year + length + budget + votes + genre ,data = df, family = binomial)
# Durbin-Watson checking
dwtest(model_1)
sum(duplicated(df))
# Set up linear regression model 2
model_2 <- glm(high_rating ~ year + length + budget
+ votes + genre,
data = df, family = binomial)
# Calculate VIF
vif(model_2)
# Calculate standardized residuals
model_residuals <- rstandard(model_1)
# Identify outliers with an absolute value greater than 3
outliers <- which(abs(model_residuals) > 3)
print(outliers)
print(df[outliers, ])
# Calculate leverage values
leverage <- hatvalues(model_1)
# Calculate the leverage threshold
threshold <- 2 * (length(coef(model_1)) / nrow(df))
# Identify points with high leverage
high_leverage <- which(leverage > threshold)
print(high_leverage)
print(df[high_leverage, c("year", "length", "budget", "votes", "high_rating")])
cooks_values <- cooks.distance(model_1)
influential_points <- which(cooks_values > 1)
print(intersect(high_leverage, influential_points))
write.csv(x = df,file = "Cleaned_data.csv",row.names = FALSE)
#| echo: false
options(scipen = 999)
# 建立二项分布广义线性模型
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df
)
# 输出模型摘要
summary(model)
# 构建基准模型和完整模型
null_model <- glm(high_rating ~ 1, family = binomial(), data = df)
# 执行似然比检验
anova_result <- anova(null_model, model, test = "Chisq")
print(anova_result)
# Wald卡方检验（Type III检验）
wald_test <- Anova(model, type = "III", test = "Wald")
print(wald_test)
library(ResourceSelection)
df$predicted_prob <- predict(model, type = "response")
# 进行 Hosmer-Lemeshow 检验（分10组）
hl_test <- hoslem.test(as.numeric(df$high_rating), df$predicted_prob, g = 10)
# 输出检验结果
print(hl_test)
library(ggplot2)
deviance_resid <- residuals(model, type = "deviance")
# 使用 ggplot2 绘制残差图
ggplot(df, aes(x = predicted_prob, y = deviance_resid)) +
geom_point(color = "blue", alpha = 0.6) +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot", x = "Predicted Probability", y = "Deviance Residuals") +
theme_minimal()
# 1. 设置图形布局（1行2列）
par(mfrow = c(1, 2))  # 一行两列，显示两张图
# 2. 绘制残差vs拟合值图
plot(model, which = 1, main = "Residuals vs Fitted")
# 3. 绘制QQ图
plot(model, which = 2, main = "Q-Q Plot")
# 预测概率
pred_prob <- predict(model, type = "response")
# 计算ROC曲线
roc_curve <- roc(response = df$high_rating, predictor = pred_prob)
plot(roc_curve)
auc_value <- auc(roc_curve)
cat("AUC =", auc_value, "\n")
# 生成预测类别
pred_class <- ifelse(pred_prob > 0.5, 1, 0)
# 计算准确率、召回率等
library(caret)
metrics <- confusionMatrix(as.factor(pred_class), df$high_rating)
print(metrics)
install.packages("brglm2")
library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
library(pROC)
library(brglm2)
df <- read.csv("dataset09.csv", stringsAsFactors = FALSE)
str(df)
summary(df)
mcar_test(df["length"])
df <- df %>% filter(!is.na(length))
df$high_rating <- ifelse(df$rating > 7, 1, 0)
df$genre <- factor(df$genre)
df$high_rating <- factor(df$high_rating)
df$years_since <- 2025 - df$year
# Set up linear regression model 1
model_1 <- glm(high_rating ~ year + length + budget + votes + genre ,data = df, family = binomial)
# Durbin-Watson checking
dwtest(model_1)
sum(duplicated(df))
# Set up linear regression model 2
model_2 <- glm(high_rating ~ year + length + budget
+ votes + genre,
data = df, family = binomial)
# Calculate VIF
vif(model_2)
# Calculate standardized residuals
model_residuals <- rstandard(model_1)
# Identify outliers with an absolute value greater than 3
outliers <- which(abs(model_residuals) > 3)
print(outliers)
print(df[outliers, ])
# Calculate leverage values
leverage <- hatvalues(model_1)
# Calculate the leverage threshold
threshold <- 2 * (length(coef(model_1)) / nrow(df))
# Identify points with high leverage
high_leverage <- which(leverage > threshold)
print(high_leverage)
print(df[high_leverage, c("year", "length", "budget", "votes", "high_rating")])
cooks_values <- cooks.distance(model_1)
influential_points <- which(cooks_values > 1)
print(intersect(high_leverage, influential_points))
write.csv(x = df,file = "Cleaned_data.csv",row.names = FALSE)
#| echo: false
options(scipen = 999)
# 建立二项分布广义线性模型
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df,(link = "logit")
)
library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
library(pROC)
library(brglm2)
df <- read.csv("dataset09.csv", stringsAsFactors = FALSE)
str(df)
summary(df)
mcar_test(df["length"])
df <- df %>% filter(!is.na(length))
df$high_rating <- ifelse(df$rating > 7, 1, 0)
df$genre <- factor(df$genre)
df$high_rating <- factor(df$high_rating)
df$years_since <- 2025 - df$year
# Set up linear regression model 1
model_1 <- glm(high_rating ~ year + length + budget + votes + genre ,data = df, family = binomial)
# Durbin-Watson checking
dwtest(model_1)
sum(duplicated(df))
# Set up linear regression model 2
model_2 <- glm(high_rating ~ year + length + budget
+ votes + genre,
data = df, family = binomial)
# Calculate VIF
vif(model_2)
# Calculate standardized residuals
model_residuals <- rstandard(model_1)
# Identify outliers with an absolute value greater than 3
outliers <- which(abs(model_residuals) > 3)
print(outliers)
print(df[outliers, ])
# Calculate leverage values
leverage <- hatvalues(model_1)
# Calculate the leverage threshold
threshold <- 2 * (length(coef(model_1)) / nrow(df))
# Identify points with high leverage
high_leverage <- which(leverage > threshold)
print(high_leverage)
print(df[high_leverage, c("year", "length", "budget", "votes", "high_rating")])
cooks_values <- cooks.distance(model_1)
influential_points <- which(cooks_values > 1)
print(intersect(high_leverage, influential_points))
write.csv(x = df,file = "Cleaned_data.csv",row.names = FALSE)
#| echo: false
options(scipen = 999)
# 建立二项分布广义线性模型
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df,method = "brglmFit"
)
# 输出模型摘要
summary(model)
# 构建基准模型和完整模型
null_model <- glm(high_rating ~ 1, family = binomial(), data = df)
# 执行似然比检验
anova_result <- anova(null_model, model, test = "Chisq")
print(anova_result)
# Wald卡方检验（Type III检验）
wald_test <- Anova(model, type = "III", test = "Wald")
print(wald_test)
library(ResourceSelection)
df$predicted_prob <- predict(model, type = "response")
# 进行 Hosmer-Lemeshow 检验（分10组）
hl_test <- hoslem.test(as.numeric(df$high_rating), df$predicted_prob, g = 10)
# 输出检验结果
print(hl_test)
library(ggplot2)
deviance_resid <- residuals(model, type = "deviance")
# 使用 ggplot2 绘制残差图
ggplot(df, aes(x = predicted_prob, y = deviance_resid)) +
geom_point(color = "blue", alpha = 0.6) +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot", x = "Predicted Probability", y = "Deviance Residuals") +
theme_minimal()
# 1. 设置图形布局（1行2列）
par(mfrow = c(1, 2))  # 一行两列，显示两张图
# 2. 绘制残差vs拟合值图
plot(model, which = 1, main = "Residuals vs Fitted")
# 3. 绘制QQ图
plot(model, which = 2, main = "Q-Q Plot")
# 预测概率
pred_prob <- predict(model, type = "response")
# 计算ROC曲线
roc_curve <- roc(response = df$high_rating, predictor = pred_prob)
plot(roc_curve)
auc_value <- auc(roc_curve)
cat("AUC =", auc_value, "\n")
# 生成预测类别
pred_class <- ifelse(pred_prob > 0.5, 1, 0)
# 计算准确率、召回率等
library(caret)
metrics <- confusionMatrix(as.factor(pred_class), df$high_rating)
print(metrics)
View(df)
str(df$high_rating)
class(df$high_rating)
table(df$high_rating)
levels(df$high_rating)  # 查看因子的水平
contrasts(df$high_rating)  # 查看 R 如何编码 0/1
pred_probs <- predict(model, type = "response")
summary(pred_probs)
table(df$genre)
library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
library(pROC)
library(brglm2)
df <- read.csv("dataset09.csv", stringsAsFactors = FALSE)
str(df)
summary(df)
mcar_test(df["length"])
df <- df %>% filter(!is.na(length))
df$high_rating <- ifelse(df$rating > 7, 1, 0)
df$genre <- factor(df$genre)
df$high_rating <- factor(df$high_rating)
df$years_since <- 2025 - df$year
# Set up linear regression model 1
model_1 <- glm(high_rating ~ year + length + budget + votes + genre ,data = df, family = binomial)
# Durbin-Watson checking
dwtest(model_1)
sum(duplicated(df))
# Set up linear regression model 2
model_2 <- glm(high_rating ~ year + length + budget
+ votes + genre,
data = df, family = binomial)
# Calculate VIF
vif(model_2)
# Calculate standardized residuals
model_residuals <- rstandard(model_1)
# Identify outliers with an absolute value greater than 3
outliers <- which(abs(model_residuals) > 3)
print(outliers)
print(df[outliers, ])
# Calculate leverage values
leverage <- hatvalues(model_1)
# Calculate the leverage threshold
threshold <- 2 * (length(coef(model_1)) / nrow(df))
# Identify points with high leverage
high_leverage <- which(leverage > threshold)
print(high_leverage)
print(df[high_leverage, c("year", "length", "budget", "votes", "high_rating")])
cooks_values <- cooks.distance(model_1)
influential_points <- which(cooks_values > 1)
print(intersect(high_leverage, influential_points))
write.csv(x = df,file = "Cleaned_data.csv",row.names = FALSE)
#| echo: false
options(scipen = 999)
# 建立二项分布广义线性模型
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df,method = "brglmFit"
)
# 输出模型摘要
summary(model)
#Standardize the budget and votes variables
df$budget_scaled <- scale(df$budget)
df$votes_scaled <- scale(df$votes)
#Increase the maximum number of iterations
model <- glm(high_rating ~ years_since + length + budget_scaled
+ votes_scaled + genre,
family = binomial(link = "logit"),
data = df, method = "brglmFit",
control = glm.control(maxit = 50))
# 构建基准模型和完整模型
null_model <- glm(high_rating ~ 1, family = binomial(), data = df)
# 执行似然比检验
anova_result <- anova(null_model, model, test = "Chisq")
print(anova_result)
# Wald卡方检验（Type III检验）
wald_test <- Anova(model, type = "III", test = "Wald")
print(wald_test)
library(ResourceSelection)
df$predicted_prob <- predict(model, type = "response")
# 进行 Hosmer-Lemeshow 检验（分10组）
hl_test <- hoslem.test(as.numeric(df$high_rating), df$predicted_prob, g = 10)
# 输出检验结果
print(hl_test)
library(ggplot2)
deviance_resid <- residuals(model, type = "deviance")
# 使用 ggplot2 绘制残差图
ggplot(df, aes(x = predicted_prob, y = deviance_resid)) +
geom_point(color = "blue", alpha = 0.6) +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot", x = "Predicted Probability", y = "Deviance Residuals") +
theme_minimal()
# 1. 设置图形布局（1行2列）
par(mfrow = c(1, 2))  # 一行两列，显示两张图
# 2. 绘制残差vs拟合值图
plot(model, which = 1, main = "Residuals vs Fitted")
# 3. 绘制QQ图
plot(model, which = 2, main = "Q-Q Plot")
# 预测概率
pred_prob <- predict(model, type = "response")
# 计算ROC曲线
roc_curve <- roc(response = df$high_rating, predictor = pred_prob)
plot(roc_curve)
auc_value <- auc(roc_curve)
cat("AUC =", auc_value, "\n")
# 生成预测类别
pred_class <- ifelse(pred_prob > 0.5, 1, 0)
# 计算准确率、召回率等
library(caret)
metrics <- confusionMatrix(as.factor(pred_class), df$high_rating)
print(metrics)
#Standardize the budget and votes variables
df$budget_scaled <- scale(df$budget)
df$votes_scaled <- scale(df$votes)
#Increase the maximum number of iterations
model_3 <- glm(high_rating ~ years_since + length + budget_scaled
+ votes_scaled + genre,
family = binomial(link = "logit"),
data = df, method = "brglmFit",
control = glm.control(maxit = 50))
#Standardize the budget and votes variables
df$budget_scaled <- scale(df$budget)
df$votes_scaled <- scale(df$votes)
#Increase the maximum number of iterations
model_3 <- glm(high_rating ~ years_since + length + budget_scaled
+ votes_scaled + genre,
family = binomial(link = "logit"),
data = df, method = "brglmFit",
control = glm.control(maxit = 50))
summary(model_3)
pred_probs <- predict(model_3, type = "response")
summary(pred_probs)
df_extreme <- df[pred_probs %in% c(0, 1), ]
print(df_extreme)
#Check which samples have predicted probabilities exactly equal to 0 or 1
pred_probs <- predict(model, type = "response")
summary(pred_probs)
df_extreme <- df[pred_probs %in% c(0, 1), ]
print(df_extreme)
library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
library(pROC)
library(brglm2)
df <- read.csv("dataset09.csv", stringsAsFactors = FALSE)
str(df)
summary(df)
mcar_test(df["length"])
df <- df %>% filter(!is.na(length))
df$high_rating <- ifelse(df$rating > 7, 1, 0)
df$genre <- factor(df$genre)
df$high_rating <- factor(df$high_rating)
df$years_since <- 2025 - df$year
# Set up linear regression model 1
model_1 <- glm(high_rating ~ year + length + budget + votes + genre ,data = df, family = binomial)
# Durbin-Watson checking
dwtest(model_1)
sum(duplicated(df))
# Set up linear regression model 2
model_2 <- glm(high_rating ~ year + length + budget
+ votes + genre,
data = df, family = binomial)
# Calculate VIF
vif(model_2)
# Calculate standardized residuals
model_residuals <- rstandard(model_1)
# Identify outliers with an absolute value greater than 3
outliers <- which(abs(model_residuals) > 3)
print(outliers)
print(df[outliers, ])
# Calculate leverage values
leverage <- hatvalues(model_1)
# Calculate the leverage threshold
threshold <- 2 * (length(coef(model_1)) / nrow(df))
# Identify points with high leverage
high_leverage <- which(leverage > threshold)
print(high_leverage)
print(df[high_leverage, c("year", "length", "budget", "votes", "high_rating")])
cooks_values <- cooks.distance(model_1)
influential_points <- which(cooks_values > 1)
print(intersect(high_leverage, influential_points))
write.csv(x = df,file = "Cleaned_data.csv",row.names = FALSE)
#| echo: false
options(scipen = 999)
# 建立二项分布广义线性模型
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df,method = "brglmFit"
)
# 输出模型摘要
summary(model)
#Check which samples have predicted probabilities exactly equal to 0 or 1
pred_probs <- predict(model, type = "response")
summary(pred_probs)
#Find and display the samples
df_extreme <- df[pred_probs %in% c(0, 1), ]
print(df_extreme)
# 构建基准模型和完整模型
null_model <- glm(high_rating ~ 1, family = binomial(), data = df)
# 执行似然比检验
anova_result <- anova(null_model, model, test = "Chisq")
print(anova_result)
# Wald卡方检验（Type III检验）
wald_test <- Anova(model, type = "III", test = "Wald")
print(wald_test)
library(ResourceSelection)
df$predicted_prob <- predict(model, type = "response")
# 进行 Hosmer-Lemeshow 检验（分10组）
hl_test <- hoslem.test(as.numeric(df$high_rating), df$predicted_prob, g = 10)
# 输出检验结果
print(hl_test)
library(ggplot2)
deviance_resid <- residuals(model, type = "deviance")
# 使用 ggplot2 绘制残差图
ggplot(df, aes(x = predicted_prob, y = deviance_resid)) +
geom_point(color = "blue", alpha = 0.6) +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot", x = "Predicted Probability", y = "Deviance Residuals") +
theme_minimal()
# 1. 设置图形布局（1行2列）
par(mfrow = c(1, 2))  # 一行两列，显示两张图
# 2. 绘制残差vs拟合值图
plot(model, which = 1, main = "Residuals vs Fitted")
# 3. 绘制QQ图
plot(model, which = 2, main = "Q-Q Plot")
# 预测概率
pred_prob <- predict(model, type = "response")
# 计算ROC曲线
roc_curve <- roc(response = df$high_rating, predictor = pred_prob)
plot(roc_curve)
auc_value <- auc(roc_curve)
cat("AUC =", auc_value, "\n")
# 生成预测类别
pred_class <- ifelse(pred_prob > 0.5, 1, 0)
# 计算准确率、召回率等
library(caret)
metrics <- confusionMatrix(as.factor(pred_class), df$high_rating)
print(metrics)
