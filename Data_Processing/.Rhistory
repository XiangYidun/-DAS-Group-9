#| echo: false
options(scipen = 999)
# 建立二项分布广义线性模型
model <- glm(
cbind(high_rating, 1-high_rating) ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df
)
# 输出模型摘要
summary(model)
# 构建基准模型和完整模型
null_model <- glm(high_rating ~ 1, family = binomial(), data = df)
# 执行似然比检验
anova_result <- anova(null_model, model, test = "Chisq")
print(anova_result)
#| echo: false
options(scipen = 999)
# 建立二项分布广义线性模型
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df
)
# 输出模型摘要
summary(model)
# 构建基准模型和完整模型
null_model <- glm(high_rating ~ 1, family = binomial(), data = df)
# 执行似然比检验
anova_result <- anova(null_model, model, test = "Chisq")
print(anova_result)
library(car)
# Wald卡方检验（Type III检验）
wald_test <- Anova(model, type = "III", test = "Wald")
print(wald_test)
library(ResourceSelection)
install.packages("ResourceSelection")
library(ResourceSelection)
# 分组数为10（通常默认）
hl_test <- hoslem.test(df$y, fitted(df), g = 10)
library(ResourceSelection)
# 确保参数顺序正确：
# 第一个参数是实际观测值（二进制数值），第二个参数是预测概率
hl_test <- hoslem.test(
x = as.numeric(data$high_rating) - 1,  # 转换为0/1数值
y = pred_prob,
g = 10  # 分组数
)
# 计算标准化Pearson残差
residuals <- residuals(df, type = "pearson")
# 绘制残差图
par(mfrow = c(2,2))
plot(full_model, which = 1:4)  # 诊断图（残差vs拟合值、QQ图等）
# 计算标准化Pearson残差
residuals <- residuals(df, type = "pearson")
# 绘制残差图
par(mfrow = c(2,2))
plot(df, which = 1:4)  # 诊断图（残差vs拟合值、QQ图等）
library(pROC)
# 预测概率
pred_prob <- predict(full_model, type = "response")
library(pROC)
# 预测概率
pred_prob <- predict(df, type = "response")
library(ResourceSelection)
df$predicted_prob <- predict(model, type = "response")
View(df)
# 进行 Hosmer-Lemeshow 检验（分10组）
hl_test <- hoslem.test(as.numeric(data$high_rating), data$predicted_prob, g = 10)
library(ResourceSelection)
df$predicted_prob <- predict(model, type = "response")
rm(predict)
# 进行 Hosmer-Lemeshow 检验（分10组）
hl_test <- hoslem.test(as.numeric(data$high_rating), data$predicted_prob, g = 10)
rm(predict)
library(ResourceSelection)
df$predicted_prob <- predict(model, type = "response")
# 进行 Hosmer-Lemeshow 检验（分10组）
hl_test <- hoslem.test(as.numeric(df$high_rating), df$predicted_prob, g = 10)
# 输出检验结果
print(hl_test)
library(ggplot2)
# 使用 ggplot2 绘制残差图
ggplot(df, aes(x = predicted_prob, y = deviance_resid)) +
geom_point(color = "blue", alpha = 0.6) +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot", x = "Predicted Probability", y = "Deviance Residuals") +
theme_minimal()
library(ggplot2)
# 使用 ggplot2 绘制残差图
ggplot(df, aes(x = predicted_prob, y = high_rating)) +
geom_point(color = "blue", alpha = 0.6) +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot", x = "Predicted Probability", y = "Deviance Residuals") +
theme_minimal()
library(ggplot2)
deviance_resid <- residuals(model, type = "deviance")
# 使用 ggplot2 绘制残差图
ggplot(df, aes(x = predicted_prob, y = deviance_resid)) +
geom_point(color = "blue", alpha = 0.6) +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot", x = "Predicted Probability", y = "Deviance Residuals") +
theme_minimal()
residuals <- residuals(full_model, type = "pearson")
residuals <- residuals(df, type = "pearson")
# 绘制残差图
par(mfrow = c(2,2))
plot(df, which = 1:4)  # 诊断图（残差vs拟合值、QQ图等）
residuals <- residuals(df, type = "pearson")
# 绘制残差图
par(mfrow = c(2,2))
plot(model, which = 1:4)  # 诊断图（残差vs拟合值、QQ图等）
residuals <- residuals(df, type = "pearson")
# 绘制残差图
par(mfrow = c(2,2))
plot(model, which = 1:4)  # 诊断图（残差vs拟合值、QQ图等）
# 1. 设置图形布局（1行2列）
par(mfrow = c(1, 2))  # 一行两列，显示两张图
# 2. 绘制残差vs拟合值图
plot(model, which = 1, main = "Residuals vs Fitted")
# 3. 绘制QQ图
plot(model, which = 2, main = "Q-Q Plot")
library(pROC)
# 预测概率
pred_prob <- predict(model, type = "response")
# 计算ROC曲线
roc_curve <- roc(response = data$high_rating, predictor = pred_prob)
library(pROC)
# 预测概率
pred_prob <- predict(model, type = "response")
# 计算ROC曲线
roc_curve <- roc(response = df$high_rating, predictor = pred_prob)
plot(roc_curve)
auc_value <- auc(roc_curve)
cat("AUC =", auc_value, "\n")
# 生成预测类别
pred_class <- ifelse(pred_prob > 0.5, 1, 0)
# 混淆矩阵
conf_matrix <- table(Predicted = pred_class, Actual = df$high_rating)
print(conf_matrix)
# 计算准确率、召回率等
library(caret)
install.packages("caret")
# 生成预测类别
pred_class <- ifelse(pred_prob > 0.5, 1, 0)
# 混淆矩阵
conf_matrix <- table(Predicted = pred_class, Actual = df$high_rating)
print(conf_matrix)
# 计算准确率、召回率等
library(caret)
metrics <- confusionMatrix(as.factor(pred_class), df$high_rating)
# 生成预测类别
pred_class <- ifelse(pred_prob > 0.5, 1, 0)
# 混淆矩阵
conf_matrix <- table(Predicted = pred_class, Actual = df$high_rating)
print(conf_matrix)
# 计算准确率、召回率等
library(caret)
metrics <- confusionMatrix(as.factor(pred_class), df$high_rating)
AIC(model)   # 越小越好
BIC(model)   # 考虑样本量惩罚，更严格
library(caret)
# 5折交叉验证
train_control <- trainControl(method = "cv", number = 5)
cv_model <- train(high_rating ~ length + budget + votes + genre + years_since,
data = data,
method = "glm",
family = "binomial",
trControl = train_control)
library(caret)
# 5折交叉验证
train_control <- trainControl(method = "cv", number = 5)
cv_model <- train(high_rating ~ length + budget + votes + genre + years_since,
data = df,
method = "glm",
family = "binomial",
trControl = train_control)
print(cv_model)
library(caret)
# 5折交叉验证
train_control <- trainControl(method = "cv",
number = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE)
cv_model <- train(high_rating ~ length + budget + votes + genre + years_since,
data = df,
method = "glm",
family = "binomial",
trControl = train_control)
library(caret)
# 5折交叉验证
train_control <- trainControl(method = "cv",
number = 5,
classProbs = TRUE)
cv_model <- train(high_rating ~ length + budget + votes + genre + years_since,
data = df,
method = "glm",
family = "binomial",
trControl = train_control)
print(cv_model)
library(caret)
# 5折交叉验证
train_control <- trainControl(method = "cv",
number = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE)
cv_model <- train(high_rating ~ length + budget + votes + genre + years_since,
data = df,
method = "glm",
family = "binomial",
trControl = train_control)
View(df)
df$high_rating <- factor(df$high_rating)
library(caret)
# 5折交叉验证
train_control <- trainControl(method = "cv",
number = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE)
cv_model <- train(high_rating ~ length + budget + votes + genre + years_since,
data = df,
method = "glm",
family = "binomial",
trControl = train_control)
# 生成预测类别
pred_class <- ifelse(pred_prob > 0.5, 1, 0)
# 混淆矩阵
conf_matrix <- table(Predicted = pred_class, Actual = df$high_rating)
print(conf_matrix)
# 计算准确率、召回率等
library(caret)
metrics <- confusionMatrix(as.factor(pred_class), df$high_rating)
print(metrics)
# 生成预测类别
pred_class <- ifelse(pred_prob > 0.5, 1, 0)
# 计算准确率、召回率等
library(caret)
metrics <- confusionMatrix(as.factor(pred_class), df$high_rating)
print(metrics)
#| echo: false
options(scipen = 999)
# 建立二项分布广义线性模型
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df
)
# 输出模型摘要
summary(model)
library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
df <- read.csv("dataset09.csv", stringsAsFactors = FALSE)
str(df)
summary(df)
mcar_test(df["length"])
df <- df %>% filter(!is.na(length))
df$high_rating <- ifelse(df$rating > 7, 1, 0)
df$genre <- factor(df$genre)
df$years_since <- 2025 - df$year
# Set up linear regression model 1
model_1 <- glm(high_rating ~ year + length + budget + votes + genre ,data = df, family = binomial)
# Durbin-Watson checking
dwtest(model_1)
sum(duplicated(df))
# Set up linear regression model 2
model_2 <- glm(high_rating ~ year + length + budget
+ votes + genre,
data = df, family = binomial)
# Calculate VIF
vif(model_2)
# Calculate standardized residuals
model_residuals <- rstandard(model_1)
# Identify outliers with an absolute value greater than 3
outliers <- which(abs(model_residuals) > 3)
print(outliers)
print(df[outliers, ])
# Calculate leverage values
leverage <- hatvalues(model_1)
# Calculate the leverage threshold
threshold <- 2 * (length(coef(model_1)) / nrow(df_coded))
# Identify points with high leverage
high_leverage <- which(leverage > threshold)
print(high_leverage)
print(df[high_leverage, c("year", "length", "budget", "votes", "high_rating")])
cooks_values <- cooks.distance(model_1)
influential_points <- which(cooks_values > 1)
print(intersect(high_leverage, influential_points))
write.csv(x = df,file = "Cleaned_data.csv",row.names = FALSE)
#| echo: false
options(scipen = 999)
# 建立二项分布广义线性模型
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df
)
# 输出模型摘要
summary(model)
# 构建基准模型和完整模型
null_model <- glm(high_rating ~ 1, family = binomial(), data = df)
# 执行似然比检验
anova_result <- anova(null_model, model, test = "Chisq")
print(anova_result)
library(car)
# Wald卡方检验（Type III检验）
wald_test <- Anova(model, type = "III", test = "Wald")
print(wald_test)
library(ResourceSelection)
df$predicted_prob <- predict(model, type = "response")
# 进行 Hosmer-Lemeshow 检验（分10组）
hl_test <- hoslem.test(as.numeric(df$high_rating), df$predicted_prob, g = 10)
# 输出检验结果
print(hl_test)
library(ggplot2)
deviance_resid <- residuals(model, type = "deviance")
# 使用 ggplot2 绘制残差图
ggplot(df, aes(x = predicted_prob, y = deviance_resid)) +
geom_point(color = "blue", alpha = 0.6) +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot", x = "Predicted Probability", y = "Deviance Residuals") +
theme_minimal()
# 1. 设置图形布局（1行2列）
par(mfrow = c(1, 2))  # 一行两列，显示两张图
# 2. 绘制残差vs拟合值图
plot(model, which = 1, main = "Residuals vs Fitted")
# 3. 绘制QQ图
plot(model, which = 2, main = "Q-Q Plot")
library(pROC)
# 预测概率
pred_prob <- predict(model, type = "response")
# 计算ROC曲线
roc_curve <- roc(response = df$high_rating, predictor = pred_prob)
plot(roc_curve)
auc_value <- auc(roc_curve)
cat("AUC =", auc_value, "\n")
df <- read.csv("dataset09.csv", stringsAsFactors = FALSE)
df <- read.csv("dataset09.csv", stringsAsFactors = FALSE)
#| echo: false
options(scipen = 999)
# 建立二项分布广义线性模型
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
method = "brglmFit",
data = df
)
library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
df <- read.csv("dataset09.csv", stringsAsFactors = FALSE)
str(df)
summary(df)
mcar_test(df["length"])
df <- df %>% filter(!is.na(length))
df$high_rating <- ifelse(df$rating > 7, 1, 0)
df$genre <- factor(df$genre)
df$years_since <- 2025 - df$year
# Set up linear regression model 1
model_1 <- glm(high_rating ~ year + length + budget + votes + genre ,data = df, family = binomial)
# Durbin-Watson checking
dwtest(model_1)
install.packages("brglm2")
#| echo: false
library(brglm2)
options(scipen = 999)
# 建立二项分布广义线性模型
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
method = "brglmFit",
data = df
)
# 输出模型摘要
summary(model)
#| echo: false
options(scipen = 999)
# 建立二项分布广义线性模型
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df
)
# 输出模型摘要
summary(model)
#| echo: false
options(scipen = 999)
df$years_since <- scale(df$years_since)
df$length <- scale(df$length)
df$budget <- scale(df$budget)
df$votes <- scale(df$votes)
# 建立二项分布广义线性模型
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df
)
# 输出模型摘要
summary(model)
View(df)
library(naniar)
library(dplyr)
library(fastDummies)
library(lmtest)
library(car)
df <- read.csv("dataset09.csv", stringsAsFactors = FALSE)
str(df)
summary(df)
mcar_test(df["length"])
df <- df %>% filter(!is.na(length))
df$high_rating <- ifelse(df$rating > 7, 1, 0)
df$genre <- factor(df$genre)
df$years_since <- 2025 - df$year
# Set up linear regression model 1
model_1 <- glm(high_rating ~ year + length + budget + votes + genre ,data = df, family = binomial)
# Durbin-Watson checking
dwtest(model_1)
sum(duplicated(df))
# Set up linear regression model 2
model_2 <- glm(high_rating ~ year + length + budget
+ votes + genre,
data = df, family = binomial)
# Calculate VIF
vif(model_2)
View(model)
View(df)
# Calculate standardized residuals
model_residuals <- rstandard(model_1)
# Identify outliers with an absolute value greater than 3
outliers <- which(abs(model_residuals) > 3)
print(outliers)
print(df[outliers, ])
# Calculate leverage values
leverage <- hatvalues(model_1)
# Calculate the leverage threshold
threshold <- 2 * (length(coef(model_1)) / nrow(df_coded))
# Calculate leverage values
leverage <- hatvalues(model_1)
# Calculate the leverage threshold
threshold <- 2 * (length(coef(model_1)) / nrow(df))
# Identify points with high leverage
high_leverage <- which(leverage > threshold)
print(high_leverage)
print(df[high_leverage, c("year", "length", "budget", "votes", "high_rating")])
cooks_values <- cooks.distance(model_1)
influential_points <- which(cooks_values > 1)
print(intersect(high_leverage, influential_points))
View(df)
write.csv(x = df,file = "Cleaned_data.csv",row.names = FALSE)
#| echo: false
options(scipen = 999)
# 建立二项分布广义线性模型
model <- glm(
high_rating ~ years_since + length + budget + votes + genre,
family = binomial(link = 'logit'),
data = df
)
# 输出模型摘要
summary(model)
# 构建基准模型和完整模型
null_model <- glm(high_rating ~ 1, family = binomial(), data = df)
# 执行似然比检验
anova_result <- anova(null_model, model, test = "Chisq")
print(anova_result)
library(car)
# Wald卡方检验（Type III检验）
wald_test <- Anova(model, type = "III", test = "Wald")
print(wald_test)
library(car)
# Wald卡方检验（Type III检验）
wald_test <- Anova(model, type = "III", test = "f")
library(car)
# Wald卡方检验（Type III检验）
wald_test <- Anova(model, type = "III", test = "F")
print(wald_test)
library(car)
# Wald卡方检验（Type III检验）
wald_test <- Anova(model, type = "III", test = "wald")
library(car)
# Wald卡方检验（Type III检验）
wald_test <- Anova(model, type = "III", test = "Wald")
print(wald_test)
# 1. 设置图形布局（1行2列）
par(mfrow = c(1, 2))  # 一行两列，显示两张图
# 2. 绘制残差vs拟合值图
plot(model, which = 1, main = "Residuals vs Fitted")
# 3. 绘制QQ图
plot(model, which = 2, main = "Q-Q Plot")
library(pROC)
# 预测概率
pred_prob <- predict(model, type = "response")
# 计算ROC曲线
roc_curve <- roc(response = df$high_rating, predictor = pred_prob)
plot(roc_curve)
auc_value <- auc(roc_curve)
cat("AUC =", auc_value, "\n")
# 生成预测类别
pred_class <- ifelse(pred_prob > 0.5, 1, 0)
# 计算准确率、召回率等
library(caret)
metrics <- confusionMatrix(as.factor(pred_class), df$high_rating)
df$genre <- factor(df$genre)
df$high_rating <- factor(df$high_rating)
# 生成预测类别
pred_class <- ifelse(pred_prob > 0.5, 1, 0)
# 计算准确率、召回率等
library(caret)
metrics <- confusionMatrix(as.factor(pred_class), df$high_rating)
print(metrics)
